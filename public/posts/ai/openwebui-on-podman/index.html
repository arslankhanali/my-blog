<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Open WebUI with Podman | AK Blogs</title>
<link rel="icon" href="/favicon.svg" sizes="any" type="image/svg+xml" /><meta property="og:url" content="//localhost:1313/posts/ai/openwebui-on-podman/">
  <meta property="og:site_name" content="AK Blogs">
  <meta property="og:title" content="Open WebUI with Podman">
  <meta property="og:description" content="Introduction Welcome to another installment in our AI series! Today, we’re going to set up Open WebUI, a powerful, self-hosted web interface for interacting with various large language models (LLMs). This tool provides a beautiful user experience similar to ChatGPT but on your own terms. We’ll be using Podman to containerize Open WebUI, making it a breeze to manage.
Why Open WebUI? Open WebUI acts as a central hub for your LLMs. It can connect to local models running on Ollama or LM Studio, as well as remote services like MaaS (Model as a Service). This flexibility allows you to experiment with different models and backends all from a single, consistent interface.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-08-08T20:52:03+10:00">
    <meta property="article:modified_time" content="2025-08-08T20:52:03+10:00">
    <meta property="article:tag" content="Openwebui">
    <meta property="article:tag" content="Podman">
    <meta property="article:tag" content="Ai">
    <meta property="article:tag" content="Ollama">
    <meta property="article:tag" content="Llm">
      <meta property="og:see_also" content="//localhost:1313/posts/ai/dify-on-podman/">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Open WebUI with Podman">
  <meta name="twitter:description" content="Introduction Welcome to another installment in our AI series! Today, we’re going to set up Open WebUI, a powerful, self-hosted web interface for interacting with various large language models (LLMs). This tool provides a beautiful user experience similar to ChatGPT but on your own terms. We’ll be using Podman to containerize Open WebUI, making it a breeze to manage.
Why Open WebUI? Open WebUI acts as a central hub for your LLMs. It can connect to local models running on Ollama or LM Studio, as well as remote services like MaaS (Model as a Service). This flexibility allows you to experiment with different models and backends all from a single, consistent interface.">

    <link rel="stylesheet" href="/css/custom.css">
    <link rel="stylesheet" href="/css/root.css">
    <link rel="stylesheet" href="/css/bundle.css">

      <script src="/js/copy-button.js"></script>
      <script src="/js/bundle.js"></script><script defer src="/js/search/flexsearch.compact.64594b125f7b78bdf4fa8316955922bbebb1cd6baef3f16654bfca20309f18f8.js" integrity="sha256-ZFlLEl97eL30&#43;oMWlVkiu&#43;uxzWuu8/FmVL/KIDCfGPg="></script>
<script defer src="/js/search/search.1d980f84df11f3eb7c8c5f17f541d49a0611608df179dd74fa7f06225eb56ace.js" integrity="sha256-HZgPhN8R8&#43;t8jF8X9UHUmgYRYI3xed10&#43;n8GIl61as4="></script>

<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Spectral:ital,wght@0,200;0,300;0,400;0,500;0,600;0,700;0,800;1,200;1,300;1,400;1,500;1,600;1,700;1,800&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Bricolage+Grotesque:opsz,wght@12..96,200..800&family=Spectral:ital,wght@0,200;0,300;0,400;0,500;0,600;0,700;0,800;1,200;1,300;1,400;1,500;1,600;1,700;1,800&display=swap" rel="stylesheet">

</head>
<body class="notransition">
  <div id="container">
    <header id="main-header"><div role="navigation" aria-label="Main">
  <div class="nav-left">
    <a href="//localhost:1313/" style="color: inherit;">AK Blogs</a>
  </div>
  <div class="nav-right">
    <div style="position:absolute;width:0px;height:0px;">
      <div id="nav-dropdown-menu" class="hidden" href="#">
    <div class="nav-item">
      <a aria-current="true" class="ancestor" href="/posts/"
      >Posts</a>
    </div>
    <div class="nav-item">
      <a href="/homelab/"
      >Homelab</a>
    </div>
    <div class="nav-item">
      <a href="/hidden/"
      >Shadow</a>
    </div>
    <div class="nav-item">
      <a href="/about/"
      >About</a>
    </div>
</div>
    </div>
    <a id="nav-dropdown-button" href="#"><svg width="20px" height="20px" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M4 6H20M4 12H20M4 18H20" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
</svg>
</a>
    <div id="nav-menu">
    <div class="nav-item">
      <a aria-current="true" class="ancestor" href="/posts/"
      >Posts</a>
    </div>
    <div class="nav-item">
      <a href="/homelab/"
      >Homelab</a>
    </div>
    <div class="nav-item">
      <a href="/hidden/"
      >Shadow</a>
    </div>
    <div class="nav-item">
      <a href="/about/"
      >About</a>
    </div>
</div>
    <a id="theme-switcher" href="#">
<svg class="light-icon" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M12 3V4M12 20V21M4 12H3M6.31412 6.31412L5.5 5.5M17.6859 6.31412L18.5 5.5M6.31412 17.69L5.5 18.5001M17.6859 17.69L18.5 18.5001M21 12H20M16 12C16 14.2091 14.2091 16 12 16C9.79086 16 8 14.2091 8 12C8 9.79086 9.79086 8 12 8C14.2091 8 16 9.79086 16 12Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
</svg>

<svg class="dark-icon" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M3.32031 11.6835C3.32031 16.6541 7.34975 20.6835 12.3203 20.6835C16.1075 20.6835 19.3483 18.3443 20.6768 15.032C19.6402 15.4486 18.5059 15.6834 17.3203 15.6834C12.3497 15.6834 8.32031 11.654 8.32031 6.68342C8.32031 5.50338 8.55165 4.36259 8.96453 3.32996C5.65605 4.66028 3.32031 7.89912 3.32031 11.6835Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
</svg>
</a>
  </div>
</div>
</header>
    <div class="flex grow">
      <div id="main-pane">
        <main id="main-content"><div class="single-header">
<ol class="breadcrumbs" itemscope itemtype="https://schema.org/BreadcrumbList">
    <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
      <a itemprop="item" href="//localhost:1313/">
        <span itemprop="name">Home</span>
      </a>
      <meta itemprop="position" content='1' />
    </li>
    <span>&nbsp»&nbsp</span>
    <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
      <a itemprop="item" href="//localhost:1313/posts/">
        <span itemprop="name">Posts</span>
      </a>
      <meta itemprop="position" content='2' />
    </li>
    <span>&nbsp»&nbsp</span>
</ol>
<h1>Open WebUI with Podman</h1><time class="dim" datetime="2025-08-08T20:52:03&#43;10:00">August 8, 2025</time><div class="term-container"><div class="tag">
        <a href="//localhost:1313/tags/openwebui/">#openwebui</a>
      </div><div class="tag">
        <a href="//localhost:1313/tags/podman/">#podman</a>
      </div><div class="tag">
        <a href="//localhost:1313/tags/ai/">#ai</a>
      </div><div class="tag">
        <a href="//localhost:1313/tags/ollama/">#ollama</a>
      </div><div class="tag">
        <a href="//localhost:1313/tags/llm/">#llm</a>
      </div></ol></div>
  <section class="page-section"><h2 id="introduction">Introduction</h2>
<p>Welcome to another installment in our AI series! Today, we&rsquo;re going to set up <strong>Open WebUI</strong>, a powerful, self-hosted web interface for interacting with various large language models (LLMs). This tool provides a beautiful user experience similar to ChatGPT but on your own terms. We&rsquo;ll be using Podman to containerize Open WebUI, making it a breeze to manage.</p>
<p><img src="https://images.unsplash.com/photo-1494869042583-f6c911f04b4c?q=80&amp;w=2940&amp;auto=format&amp;fit=crop&amp;ixlib=rb-4.1.0&amp;ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D" alt="Open WebUI"></p>
<h3 id="why-open-webui">Why Open WebUI?</h3>
<p>Open WebUI acts as a central hub for your LLMs. It can connect to local models running on <strong>Ollama</strong> or <strong>LM Studio</strong>, as well as remote services like <strong>MaaS</strong> (Model as a Service). This flexibility allows you to experiment with different models and backends all from a single, consistent interface.</p>
<h2 id="step-1-pulling-the-open-webui-image">Step 1: Pulling the Open WebUI Image</h2>
<p>First, we need to pull the Open WebUI container image from its public registry. Podman makes this simple and efficient.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># This command fetches the latest main version of the Open WebUI image from GitHub&#39;s container registry.</span>
</span></span><span style="display:flex;"><span>podman pull ghcr.io/open-webui/open-webui:main
</span></span></code></pre></div><h2 id="step-2-running-the-container">Step 2: Running the Container</h2>
<p>Now, let&rsquo;s run the container with all the necessary configurations. We&rsquo;ll map a port, set environment variables, and create a persistent volume for data.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>podman run -d <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --name open-webui <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  -p 3001:8080 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  -e OLLAMA_BASE_URL<span style="color:#f92672">=</span>http://192.168.50.50:11434 <span style="color:#ae81ff">\ </span><span style="color:#75715e"># If you have Ollama</span>
</span></span><span style="display:flex;"><span>  -e OPENAI_API_KEY<span style="color:#f92672">=</span>dummykey <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  -v open-webui:/app/backend/data:z <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --restart<span style="color:#f92672">=</span>always <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  ghcr.io/open-webui/open-webui:main
</span></span></code></pre></div><h2 id="step-3-accessing-open-webui">Step 3: Accessing Open WebUI</h2>
<p>Once the container is running, you can access the web interface by navigating to your host machine&rsquo;s IP address and the mapped port.</p>
<p><a href="http://192.168.50.200:3001">http://192.168.50.200:3001</a></p>
<h3 id="initial-setup">Initial Setup</h3>
<p>The first time you visit the page, you&rsquo;ll be prompted to create a user account. After creating your account, you can log in and access the admin settings to configure your LLM connections.</p>
<h2 id="step-4-configuring-connections">Step 4: Configuring Connections</h2>
<p>In the Open WebUI admin panel, you can add various connections to different LLM services.</p>
<ul>
<li>Add connections: Settings -&gt; Admin Panel -&gt; Conenctions
<a href="http://192.168.50.200:3001/admin/settings/connections">http://192.168.50.200:3001/admin/settings/connections</a></li>
</ul>
<p>e.g. Notice URL format</p>
<blockquote>
<p>OLLAMA: http://192.168.50.50:11434   # &lt; &mdash; From Ollama CLI   <br>
OPENAI: http://192.168.50.50:1234/v1   # &lt; &mdash; From LMStudio</p></blockquote>
<p><img src="/ai/open_webui.png" alt="a"></p>
<div style="background-color: #d3cd22ff; padding: 2px; border-left: 10px solid red;">
<p>⚠️ WARNING:
Remember to use http or https as appropriate for your connection. Always use the correct port and make sure your firewall is configured to allow traffic on these ports.</p>
</div>
<p>You now have a fully functional Open WebUI instance running on your server, giving you a powerful tool to manage and interact with all your LLMs in one place!</p>
</section></main>
        <footer id="main-footer">
<script src="/js/copy-button.min.4876b98121977026b3ce53c9cb225d818299becf2f6ba9c345fdfbc99911d6dd.js" integrity="sha256-SHa5gSGXcCazzlPJyyJdgYKZvs8va6nDRf37yZkR1t0="></script>
</footer>
      </div><aside id="side-pane" class="side-sticky"><div class="side-content">
      <h3>Disclaimer</h3><p><ul>
<li>This content is for educational and experimental purposes only, provided “as is” without warranties. You are solely responsible for how you use it</li>
</ul>
</p>
    </div><div class="side-details">
    <span>386 words</span>
    <span>2 - 3 minutes read</span><div class="side-details-taxonomy">
        <small>series: 
          <span class="details-taxonomy"><a href="//localhost:1313/series/ai">AI</a></span></small>
      </div><div class="side-details-taxonomy">
        <small>topics: 
          <span class="details-taxonomy"><a href="//localhost:1313/topics/ai-applications">ai-applications</a></span><span class="details-taxonomy"><a href="//localhost:1313/topics/containerization">containerization</a></span></small>
      </div></div><h3>Table Of Contents</h3><nav id="TableOfContents">
  <ul>
    <li><a href="#introduction">Introduction</a>
      <ul>
        <li><a href="#why-open-webui">Why Open WebUI?</a></li>
      </ul>
    </li>
    <li><a href="#step-1-pulling-the-open-webui-image">Step 1: Pulling the Open WebUI Image</a></li>
    <li><a href="#step-2-running-the-container">Step 2: Running the Container</a></li>
    <li><a href="#step-3-accessing-open-webui">Step 3: Accessing Open WebUI</a>
      <ul>
        <li><a href="#initial-setup">Initial Setup</a></li>
      </ul>
    </li>
    <li><a href="#step-4-configuring-connections">Step 4: Configuring Connections</a></li>
  </ul>
</nav><h3>Related</h3>
    <ul><li><a href="/posts/ai/dify-on-podman/">Dify: A Podman Deployment Guide</a></li><li><a href="/hidden/podman-arr-stack-configuration/">Arr Stack - Configuration</a></li><li><a href="/hidden/podman-arr-stack/">Arr stack - Installation</a></li><li><a href="/hidden/podman-101/">Podman 101 - Always Run Rootless!</a></li><li><a href="/hidden/podman-traefik/">Traefik on Podman with Local Certificates</a></li></ul></aside></div>
  </div>
</body>
</html>
